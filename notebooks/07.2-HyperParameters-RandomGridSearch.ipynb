{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Parameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Parameter Search\n",
    "\n",
    "When you cannot do a comprehensive parameter search due to the number of parameters growing _really_ fast, then, we need to be _smarter_ about grid search. I.e. decrease the parameter search space without (hopefully) giving up too much performance. The performance of the classifier may not match to the grid search, but it may often approach it, for a fraction of the computation time. \n",
    "\n",
    "RandomizedParameterSearch in scikit-learn does the hard work for us and without losing too much performance, we have similar results to the GridSearch in a much more efficient and faster way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import randint as sp_randint\n",
    "import sklearn\n",
    "from sklearn import cross_validation\n",
    "from sklearn import datasets\n",
    "from sklearn import ensemble\n",
    "from sklearn import grid_search\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "_DATA_DIR = 'data'\n",
    "_DATA_PATH = os.path.join(_DATA_DIR, 'titanic.csv')\n",
    "\n",
    "# To encode categorical variables\n",
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df['row.names']\n",
    "df['pclass'] = label_encoder.fit_transform(df.pclass)\n",
    "df['embarked'] = label_encoder.fit_transform(df.embarked)\n",
    "df['sex'] = label_encoder.fit_transform(df.sex)\n",
    "def convert_age(number):\n",
    "    try:\n",
    "        number = int(number)\n",
    "    except ValueError:\n",
    "        number = 0\n",
    "    return number\n",
    "\n",
    "def extract_home_destination(address):\n",
    "    try:\n",
    "        address = address.split(',')[-1]\n",
    "    except AttributeError:\n",
    "        address = ''\n",
    "    return address\n",
    "\n",
    "df.age = df.age.apply(convert_age)\n",
    "# Preprocess first\n",
    "df['home.dest'] = df['home.dest'].apply(extract_home_destination)\n",
    "df['destination'] = label_encoder.fit_transform(df['home.dest'])\n",
    "del df['home.dest']\n",
    "del df['boat']\n",
    "del df['ticket']\n",
    "del df['name']\n",
    "del df['room']\n",
    "y = np.array(df.survived.tolist())\n",
    "del df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_names = ['pclass', 'age', 'embarked', 'sex', 'destination']\n",
    "X = df[feature_names].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 995.277484894 seconds\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "              'learning_rate': [0.1, 0.05, 0.01],\n",
    "              'max_depth': [4, 6],\n",
    "              'min_samples_leaf': [1, 2, 3, 4, 9, 15],\n",
    "              'n_estimators': [1000, 2000, 3000],\n",
    "              }\n",
    "\n",
    "est = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "randomized_search = grid_search.RandomizedSearchCV(est, param_distributions=param_grid,\n",
    "    n_iter=n_iter_search, n_jobs=4).fit(X_train, y_train)\n",
    "\n",
    "gs_cv = grid_search.GridSearchCV(est, param_grid, n_jobs=4).fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print('It took {} seconds'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01,\n",
       " 'max_depth': 4,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 2000}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best hyperparameter setting\n",
    "randomized_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80476190476190479"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.77905, std: 0.01553, params: {'n_estimators': 3000, 'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 3},\n",
       " mean: 0.78000, std: 0.02100, params: {'n_estimators': 3000, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 9},\n",
       " mean: 0.78286, std: 0.00841, params: {'n_estimators': 3000, 'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 2},\n",
       " mean: 0.80286, std: 0.00233, params: {'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_leaf': 3},\n",
       " mean: 0.79238, std: 0.00943, params: {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 6, 'min_samples_leaf': 2},\n",
       " mean: 0.78571, std: 0.00404, params: {'n_estimators': 3000, 'learning_rate': 0.05, 'max_depth': 6, 'min_samples_leaf': 2},\n",
       " mean: 0.77714, std: 0.01234, params: {'n_estimators': 3000, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 2},\n",
       " mean: 0.80286, std: 0.00467, params: {'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_leaf': 1},\n",
       " mean: 0.78476, std: 0.01720, params: {'n_estimators': 2000, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 9},\n",
       " mean: 0.77238, std: 0.00883, params: {'n_estimators': 2000, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 3},\n",
       " mean: 0.78381, std: 0.00943, params: {'n_estimators': 2000, 'learning_rate': 0.05, 'max_depth': 6, 'min_samples_leaf': 4},\n",
       " mean: 0.78190, std: 0.01655, params: {'n_estimators': 1000, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 9},\n",
       " mean: 0.78762, std: 0.01197, params: {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 4},\n",
       " mean: 0.80381, std: 0.00943, params: {'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_leaf': 9},\n",
       " mean: 0.79619, std: 0.00713, params: {'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 6, 'min_samples_leaf': 3},\n",
       " mean: 0.80286, std: 0.01234, params: {'n_estimators': 2000, 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_leaf': 3},\n",
       " mean: 0.79143, std: 0.01400, params: {'n_estimators': 2000, 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_leaf': 9},\n",
       " mean: 0.77810, std: 0.02117, params: {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 9},\n",
       " mean: 0.78762, std: 0.01984, params: {'n_estimators': 1000, 'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 3},\n",
       " mean: 0.80476, std: 0.01197, params: {'n_estimators': 2000, 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_leaf': 1}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_search.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between Grid Search and Randomized Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = ensemble.RandomForestClassifier()\n",
    "\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for ii, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {}\".format(ii + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {}\\n\".format(score.parameters))\n",
    "\n",
    "param_grid = {\"max_depth\": [3, 2, 1, None],\n",
    "              \"max_features\": [1, 2, 3, 4],\n",
    "              \"min_samples_split\": [1, 2, 3, 4],\n",
    "              \"min_samples_leaf\": [1, 2, 3, 4],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "              'n_estimators': [50, 100, 1000, 2000, 3000],\n",
    "}\n",
    "\n",
    "n_iter_search = 20\n",
    "random_search = grid_search.RandomizedSearchCV(clf, param_distributions=param_grid,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time.time()\n",
    "random_search.fit(X, y)\n",
    "end = time.time()\n",
    "print(\"RandomizedSearchCV took {0:.2f} seconds for {1} candidates\"\n",
    "      \" parameter settings.\".format((end - start), n_iter_search))\n",
    "report(random_search.grid_scores_)s\n",
    "\n",
    "\n",
    "param_grid = {\"max_depth\": [3, 2, 1, None],\n",
    "              \"max_features\": [1, 2, 3, 4],\n",
    "              \"min_samples_split\": [1, 2, 3, 4],\n",
    "              \"min_samples_leaf\": [1, 2, 3, 4],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "              'n_estimators': [50, 100, 1000, 2000, 3000],\n",
    "}\n",
    "\n",
    "gs = grid_search.GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time.time()\n",
    "gs.fit(X, y)\n",
    "end = time.time()\n",
    "\n",
    "print(\"GridSearchCV took {0:.2f} seconds for {1} candidate parameter settings.\".format(\n",
    "      (end - start, len(gs.grid_scores_))))\n",
    "report(gs.grid_scores_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
