{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every classifier, there are __a lot of__ parameters to be optimized if we want the best performance from a given model.\n",
    "These can include: \n",
    "- The type of Kernel used in a SVM.\n",
    "- Regularization terms, loss penalties.. (L1,L2..) \n",
    "- Use of different feature transformations (normalizing, scaling, feature extraction..) \n",
    "etc' . \n",
    "\n",
    " This is time consuming(computation, storage and reporting) but CRUCIAL for most (but not all) models! \n",
    " Consider these parameters an extra burden when you try to choose an optimal classifier out of multiple classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn provides a grid search with cross validation in `GridSearchCV`. This automatically finds the best hyperparameters, tested via cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it may take a lot of time to do - the number of parameters to be tested increases combinatorically (e.g. 2*5*3 = 30!). You may want to use a powerful multicore machine to do the grid search in the parameter space, and be \"smart\" about it in general (only tuning important parameters). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import cross_validation\n",
    "from sklearn import datasets\n",
    "from sklearn import ensemble\n",
    "from sklearn import grid_search\n",
    "from sklearn import metrics\n",
    "import time\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading Cal. housing from http://lib.stat.cmu.edu/modules.php?op=modload&name=Downloads&file=index&req=getit&lid=83 to C:\\Users\\User\\scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "california_housing = datasets.california_housing.fetch_california_housing()\n",
    "california_housing_data = california_housing['data']\n",
    "california_housing_labels = california_housing['target']# 'target' variables\n",
    "california_housing_feature_names = california_housing['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(california_housing_data,\n",
    "                                                    california_housing_labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create a grid search object, it is necessary to pass the estimator, the parameters we want to optimize for that estimator, and optionally `n_job` in order to parallellize the parameter search. Grid search in parameter space is embarrasingly parallel by nature as different parameter combinations are independent from each other. \n",
    "You can also pass different scoring functions if you want to use another scoring function to optimize the best parameters for your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "              'learning_rate': [0.1, 0.05, 0.01],\n",
    "              'max_depth': [4, 6],\n",
    "              'min_samples_leaf': [3, 9, 15],\n",
    "              'n_estimators': [1000, 2000, 3000],\n",
    "              }\n",
    "\n",
    "est = ensemble.GradientBoostingRegressor()\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "gs_cv = grid_search.GridSearchCV(est, param_grid, n_jobs=-2).fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print('It took {:.2f} seconds'.format(end_time - start_time))\n",
    "# best hyperparameter setting\n",
    "gs_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to get scores for each different parameter combination, `grid_scores_` attribute of GridSearch object provides a nice way to provide all of the scores for each parameter combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_cv.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Parameter Search\n",
    "\n",
    "When you cannot do a comprehensive parameter search due to the number of parameters growing _really_ fast, then, we need to be _smarter_ about grid search. I.e. decrease the parameter search space without (hopefully) giving up too much performance. The performance of the classifier may not match to the grid search, but it may often approach it, for a fraction of the computation time. \n",
    "\n",
    "**RandomizedParameterSearch** in scikit-learn does this work for us and without losing too much performance, we have similar results to the GridSearch in a much faster way. Many other optimization methods exist, notably Bayesian methods and Spearmint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "              'learning_rate': [0.1, 0.05, 0.01],\n",
    "              'max_depth': [4, 6],\n",
    "              'min_samples_leaf': [1, 2, 3, 4, 9, 15],\n",
    "              'n_estimators': [1000, 2000, 3000],\n",
    "              }\n",
    "\n",
    "est = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "# run randomized search\n",
    "n_iter_search = 10\n",
    "randomized_search = grid_search.RandomizedSearchCV(est, param_distributions=param_grid,\n",
    "    n_iter=n_iter_search, n_jobs=4).fit(X_train, y_train)\n",
    "\n",
    "gs_cv = grid_search.GridSearchCV(est, param_grid, n_jobs=4).fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print('It took {} seconds'.format(end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
